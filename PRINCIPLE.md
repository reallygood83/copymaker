일단 결론부터 말하면,
**“GPT 표절률”이라는 건 마법 같은 숫자가 아니라, 여러 가지 ‘유사도 지표’를 합쳐서 만든 점수**예요.
그리고 그 원리를 잘 뜯어보면, 학생들이 슬쩍 베껴 쓰는 걸 꽤 잘 잡아낼 수 있는 **표절 검사기**를 설계할 수 있습니다.

아래에서 진짜 실무 수준으로 단계별로 해부해볼게요.
(코딩 언어나 프레임워크는 안 정해져 있다고 가정하고, 알고리즘/로직 중심으로 설명할게요.)

---

## 1. 먼저 용어 정리: “표절률” vs “AI/GPT 생성률”

### 1) 표절률 (plagiarism / similarity score)

보통 Turnitin 같은 시스템이 보여주는 건 **“이 글이 다른 텍스트와 얼마나 겹치는지”**를 %로 수치화한 거예요.

* 기준:

  * 인터넷/논문/과제 DB에 있는 *기존 텍스트*
  * 같은 수업·학교의 다른 학생 과제
* 측정 대상:

  * 문장/구/단어 수준의 **직접 복사**
  * 구조만 살짝 바꾼 **의미적(semantic) 표절**까지 점점 포함하는 추세([Frontiers][1])

즉, “표절률”은:

> 문서 전체 중 **‘어디선가 본 적 있는 패턴으로 강하게 의심되는 부분’의 비율**

이라고 보면 됩니다.

---

### 2) GPT/AI 생성률 (AI-generated probability)

최근 등장한 “GPT 탐지기”는 전혀 다른 걸 봅니다.

* “이 글이 **LLM(예: GPT)**이 쓴 것처럼 보이는가?”
* 글의 **확률 분포, 퍼플렉시티(perplexity), burstiness(단어/문장 다양성)** 등을 가지고 판별([Hastewire][2])

그래서:

* 표절률 = **“남의 글을 베꼈는지”** 중심
* AI 생성률 = **“사람이 쓴 글 같냐, GPT가 쓴 글 같냐”** 중심

당신이 만들고 싶어 하는 건:

> 학생이 **남의 글이나 GPT 글을 그대로 가져와 쓰지 못하도록** 막는 도구

이니까,
**① 전통적인 표절 검출 + ② AI 생성 의심 신호**를 둘 다 고려하는 하이브리드 구조를 설계하는 게 실무적으로 가장 합리적입니다.([PLOS][3])

---

## 2. “표절률”이 실제로 계산되는 구조 (클래식 표절 검사기 아키텍처)

여기부터가 핵심입니다.
일반적인 표절 검사 시스템은 크게 보면 아래 5단계를 거칩니다.

1. **코퍼스 수집 (비교 대상 텍스트 모음)**
2. **전처리 (정규화, 형태소 분석, 토큰화)**
3. **특징 추출 (n-gram, tf-idf, 임베딩 등)**
4. **유사도 계산 (문장·구 단위)**
5. **문서 전체 표절률 산출 + 리포트 생성**

### 2-1. 코퍼스 수집

**표절률은 “비교 대상”이 있어야만 의미가 있어요.**

* 내부 DB:

  * 같은 과목/학교의 과제
  * 과거 학기 과제
* 외부 DB:

  * 오픈 액세스 논문, 리포트
  * 웹 페이지 크롤링
* 교사가 별도로 올리는 PDF, 교재, 참고자료

> 구조적으로는 “검색 엔진” + “벡터 DB” 조합으로 구현한다고 생각하면 편합니다.([ACM Digital Library][4])

---

### 2-2. 전처리: 한국어 기준 상세 단계

한국어 표절 검사기는 **형태소 분석**이 매우 중요합니다.

1. **문자 수준 정규화**

   * 공백·특수문자 정리
   * 전각/반각, 유니코드 정규화
   * “학습자분석” vs “학습자 분석” 같은 공백 차이 통일

2. **문장 분할**

   * 마침표, 물음표, 느낌표, 줄바꿈 기준
   * 문장단위로 쪼개 놓으면 나중에 *“어떤 문장이 문제인지”* 보고하기 쉬움

3. **형태소 분석 / 토큰화**

   * 예: “디지털 역량이 낮은 집단을 대상으로”
     → [디지털/NNG, 역량/NNG, 낮/VV, -은/ETM, 집단/NNG, 대상/NNG, -으로/JKB …]
   * 어미/조사는 필요에 따라 제거하고, **기본형(어간)** 위주로 비교

4. **불용어(stopword) 처리**

   * “그리고, 그러나, 또한, 이러한, 따라서…” 등 의미가 약한 접속/기능 단어는 경우에 따라 제외
   * 다만, **스타일 분석**할 때는 오히려 이런 기능어가 중요해질 수 있음

5. **문서 → 토큰 시퀀스 / 문장 리스트로 변환**

---

### 2-3. 특징 추출 (표절률의 “재료” 만들기)

현대 표절 검사기는 보통 **세 가지 층위의 특징**을 같이 씁니다.([ERIC][5])

1. **문자/단어 기반 n-gram (shingle)**

   * 예: 토큰 시퀀스에서 5-gram:

     * [성인, 청소년, 평생교육, 프로그램, 설계]
     * [청소년, 평생교육, 프로그램, 설계, 고려] …
   * 문서 A와 문서 B의 n-gram 집합을 만들어 **Jaccard 유사도** 등으로 비교:
     [
     J(A,B) = \frac{|A \cap B|}{|A \cup B|}
     ]
   * 장점: 직복사에 굉장히 강함
   * 단점: 단어만 조금 바꿔도(동의어 치환) 유사도가 확 떨어짐

2. **통계 기반: TF-IDF 벡터**

   * 각 문서/문장을 **고차원 벡터**로 바꾼 뒤,
   * **코사인 유사도**로 비교:
     [
     \text{cosine}(A,B) = \frac{A\cdot B}{|A||B|}
     ]
   * 주로 문단/문서 수준 비교에 사용

3. **의미(semantic) 기반: 임베딩 벡터**

   * BERT/SBERT/KoBERT 등으로 **문장/단락 임베딩** 생성
   * 사람이 보기엔 “문장 구조는 바뀌었지만 말하는 내용은 같다”를 잡아내는 데 필수적
   * 예:

     * “요구분석은 현재와 이상적인 상태의 차이를 찾는 과정이다.”
     * “지금 수준과 목표 수준의 간극을 파악하는 것이 요구분석이다.”
       → n-gram은 낮지만, 임베딩 코사인 유사도는 높게 나옴([HogoNext][6])

실무에서는:

> **n-gram 기반 “직복사 탐지” + 임베딩 기반 “의미 표절 탐지”**를 섞어서 점수를 만드는 게 가장 안정적입니다.([Frontiers][1])

---

### 2-4. 문장/구 단위 유사도 계산

실제 표절률은 **문장 또는 일정 길이의 “청크(chunk)” 단위**로 계산합니다.

#### (1) 후보 문서 검색

1. 학생 글의 각 문장/청크 → 간단한 특징(n-gram, 키워드 등)
2. 인덱스된 코퍼스에서 **검색엔진처럼** 비슷한 문서 Top-K만 뽑음

   * BM25, inverted index, 또는 LSH(MinHash) 등 사용

#### (2) 세밀 비교

후보 문서가 좁혀지면, 그 안에서:

* 각 문장 쌍에 대해:

  * n-gram Jaccard
  * TF-IDF 코사인
  * 임베딩 코사인
  * * 필요하면 edit distance(Levenshtein)로 “약간 다른 복사” 탐지([ERIC][5])

그리고 예를 들어 아래처럼 **룰 기반 decision**을 만들 수 있습니다:

```text
if (Jaccard_n_gram ≥ 0.8) and (문장 길이 ≥ 10 토큰):
    라벨 = "직접 복사"
elif (임베딩 코사인 ≥ 0.85) and (Jaccard_n_gram ≥ 0.4):
    라벨 = "부분 수정 표절"
elif (임베딩 코사인 ≥ 0.9) and (Jaccard_n_gram < 0.3):
    라벨 = "의미 표절(강한 의심)"
else:
    라벨 = "정상 또는 약한 유사"
```

이렇게 문장/청크별로 “표절 의심 여부 + 강도” 라벨을 붙여나갑니다.

---

### 2-5. 최종 “표절률 %” 계산 로직

표절률은 단순히 “의심 문장 개수 / 전체 문장 개수”가 아니라,
**“해당 구간이 문서에서 차지하는 비율”**로 계산하는 게 보통입니다.

예시 알고리즘:

1. 문서를 문장 혹은 토큰 길이로 나누어 전체 길이 (L)을 구함.
2. 각 문장/청크에 대해:

   * 길이: (l_i)
   * 라벨: 직복사(가중치 1.0), 부분 수정 표절(0.7), 의미 표절(0.5) 등 가중치 부여
3. 아래와 같이 점수 합산:
   [
   \text{표절 점수} = \frac{\sum_i (l_i \times w_i)}{L} \times 100 (%)
   ]

그리고 리포트는 보통:

* 전체 표절률: 예) 28%
* 출처별 유사도:

  * 웹사이트 A: 17%
  * 논문 B: 8%
  * 과거 과제 C: 3%
* 색깔 하이라이트로 “어디서 가져온 것 같은지” 시각화

> 여기서 중요한 건, **표절률 = ‘판결’이 아니라 ‘신호’**라는 점이에요.
> 최종 판단은 항상 사람이 해야 하고, 인용/참고문헌을 제대로 밝힌 부분은 감점에서 제외할 필요가 있습니다.([ACM Digital Library][4])

---

## 3. GPT/AI 텍스트 탐지 원리: “GPT 표절률”과 연결

학생들이 요즘 하는 “표절”은 크게 두 가지입니다:

1. 남의 글 복붙 + 약간 수정
2. GPT가 써준 글을 거의 그대로 제출

1번은 위에 설명한 **전통적 표절 검사**로 어느 정도 잡을 수 있지만,
2번은 외부에 **“원본” 문서가 없으니** 일반 표절 검사만으로는 안 잡힐 수 있습니다.([PLOS][3])

그래서 등장한 게 **AI/GPT 탐지기**이고, 이들은 보통 이런 원리를 씁니다:([Hastewire][2])

1. **언어 모델 기반 퍼플렉시티(perplexity)**

   * 어떤 문장에 대해 “다음 단어가 나올 확률 분포”를 계산
   * GPT가 만든 문장은 **모델 입장에서 지나치게 ‘예측하기 쉬운’ 패턴**을 보이는 경우가 많음 → 낮은 퍼플렉시티
   * 반대로 인간 글은 오탈자, 비선형 구조, 이상한 연결 등으로 **예측 불가능성이 더 큼**

2. **burstiness / 다양성 지표**

   * 문장 길이 분포, 단어 다양성, 희귀 단어 사용 비율 등을 복합적으로 살펴봄
   * AI 글은 **어느 정도 일정한 리듬과 균질성**을 갖는 경향이 있음

3. **특징 기반 분류기**

   * 위의 수치들 + n-gram 통계 + 문체 특성(기능어 분포 등)을 feature로 뽑고
   * “AI / Human” 이진 분류 모델을 학습

하지만 최근 연구들에서:

* 다양한 LLM이 섞여 나오고,
* 학생들이 일부만 수정·섞어서 쓰는 경우가 많아서,

> **AI 탐지기는 단독으로 신뢰하기 어렵고, 오탐(false positive)·미탐(false negative) 이슈가 크다**는 결과들이 꾸준히 보고되고 있습니다.([SpringerLink][7])

그래서 실무에서는:

> **“AI 생성 의심 점수”는 참고 지표로만 쓰고,
> 최종 제재는 표절률 + 과제 유형 + 학생 기존 글과의 차이**까지 종합해서 결정하는 방향이 권장됩니다.([Write My Way AI][8])

---

## 4. “학생용 표절 검사기”를 만들 때의 실무 설계안

이제 위의 원리를 바탕으로,
실제 서비스/시스템 관점에서 “어떻게 구성할까?”를 단계별로 정리해볼게요.

### 4-1. 전체 구조(아키텍처)

1. **입력 레이어**

   * 웹/앱에서 과제 텍스트 업로드 (txt, docx, pdf 등)
   * 업로드 즉시 텍스트 추출 + 인코딩 정규화

2. **NLP·분석 엔진**

   * 전처리 (문장 분할 + 형태소 분석)
   * 특징 추출 (n-gram, TF-IDF, 임베딩)
   * 코퍼스 검색 + 유사도 계산
   * AI 생성 의심 점수 계산(선택)

3. **스토리지/인덱스**

   * 학생 과제 DB (과거 과제가 가장 중요한 내부 코퍼스)
   * 외부 자료 인덱스 (웹/논문)
   * 벡터 인덱스(임베딩 검색용)

4. **리포트/관리 UI**

   * 교사용: 상세 출처·문장 하이라이트 + 원본 비교
   * 학생용: 전체 유사도/표절률 + 인용 가이드

---

### 4-2. 학생 “표절 방지” 기능까지 포함하려면

단순히 “잡는 것”을 넘어서 **“못 하게 만드는” 설계**도 가능합니다.

1. **사전 자기 점검 모드**

   * 학생이 제출 전에 본인이 직접 검사해보도록 허용
   * 결과 화면에:

     * “이 부분은 출처 표기가 필요합니다.”
     * “이 문장은 ○○ 자료와 거의 동일합니다. 요약/재작성하거나 인용으로 표시하세요.”
   * 이렇게 하면 학생이 **“의도치 않은 표절”**을 줄이는 데도 도움이 됨

2. **학생 본인 글과의 비교 (저자 지문, writing fingerprint)**

   * 동일 학생의 과거 과제에서:

     * 평균 문장 길이
     * 자주 쓰는 표현/오탈자 패턴
     * 기능어(그리고, 그런데, 즉, 따라서 등) 사용 특징
   * 등으로 “저자 프로파일”을 만들고,
   * 새로운 과제가 이 프로파일과 크게 어긋나면 “AI/대리 작성 의심” 플래그만 표시([Write My Way AI][8])

3. **교사/관리자용 경고 레벨**

   * 예:

     * Level 1: 표절률 10~20% (일반적인 인용/배경 설명 수준)
     * Level 2: 20~40% (주의 필요)
     * Level 3: 40% 이상 또는 특정 구간 100% 매칭 (강력 의심)
   * * AI 의심 점수가 높으면 별도 아이콘/경고만 추가

---

## 5. 예시 문단에 적용하면, 시스템은 대략 이렇게 본다

당신이 올린 평생교육 프로그램 글을 예로 들면, 알고리즘은 대략 다음처럼 처리합니다:

1. **문장 분할**

   * “주장 … 요소는 학습자 분석이다.”
   * “요구분석은 현재 상태…”
   * “근거 평생교육 방법론에서…”
   * “이는 UNESCO가 강조하는…”
   * “예시/대안 만약 온라인 협업 도구를…”
     → 5~7개의 문장/청크로 분리

2. **각 문장에 대해:**

   * n-gram 기반으로 웹/논문·보고서 DB에서 비슷한 문장 검색
   * 예를 들어, “요구분석은 현재 상태와 바람직한 상태 간의 격차를 규명하는 활동이며…” 같은 정의형 문장은

     * 교육학 교재/논문과 n-gram 유사도가 높게 나올 수 있음
   * 반면, “중장년층 학습자의 디지털 역량이 청소년 그룹에 비해 현저히 낮음을 확인할 수 있습니다.” 같은 문장은

     * 내용은 흔하지만 표현은 비교적 구체적이라 유사도는 중간 정도

3. **임베딩 기반 의미 비교**

   * “학습자 분석”의 필요성을 설명하는 근거 부분은,

     * 다른 학자 논문에서 비슷한 내용을 말하고 있으면 **의미 유사도**가 높게 나올 수 있음.
   * 이때, 실제로 문장을 직접 베낀 것인지,
     아니면 개념을 이해하고 자기 말로 쓴 것인지가 중요.

4. **최종 표절률 계산**

   * 정의/개념 설명 부분처럼 많은 사람이 비슷하게 쓰는 문장은

     * 일부 유사도는 자연스럽게 나올 수 있기 때문에,
     * 시스템 설계 시 “일반지식 영역”으로 완화해 보는 옵션도 고려 가능

---

## 6. 현실적인 한계와 운영 상 주의점

마지막으로, 시스템을 설계할 때 꼭 알고 있어야 할 점:

1. **어떤 알고리즘도 100% 올바른 판결을 내리진 못함**

   * 특히 AI 생성 탐지는 **거짓 양성/음성 비율이 꽤 높음**([SpringerLink][7])

2. **표절률 %는 “정확한 죄의 양”이 아니라 “검토해야 할 위험도”**

   * 예: 문헌고찰 과제는 표절률이 자연히 올라갈 수밖에 없음
   * 반대로 5%라도, 핵심 주장 부분이 통째로 베껴졌다면 심각한 문제

3. **정책과 교육이 함께 가야 함**

   * 학생이 “어떻게 인용하고, 어떻게 요약해야 안전한지”를 미리 교육
   * 검사기는 **벌주는 도구**가 아니라 **지도 도구**로 먼저 사용

---

## 7. 요약 정리

* “GPT 표절률”을 만들려면, 결국

  * **텍스트 유사도 기반 표절률** +
  * **AI 생성 의심 점수(퍼플렉시티/문체 특징 등)**
    두 축을 결합해야 합니다.
* 실무적으로는:

  1. 전처리(문장 분할, 형태소 분석)
  2. n-gram / TF-IDF / 임베딩 특징 추출
  3. 코퍼스 검색 + 문장/청크 단위 유사도 계산
  4. 가중치 기반으로 전체 표절률 % 산출
  5. AI 탐지 결과는 참고 지표로만 사용
* 운영 단계에서는:

  * **학생 자기 점검 모드** + **저자 지문(학생 고유 문체)** + **교사용 상세 리포트**를 결합하면
    “표절을 못 하도록” 막는 데 꽤 강력한 시스템이 됩니다.

---

관련해서 **구현 도식(예: 플로우차트)**나
“파이썬으로 임베딩 기반 표절률 계산하는 간단한 프로토타입 설계”가 필요하면,
다음 단계로 그 부분만 따로 쪼개서 설계 예시도 만들어 줄게요.

그리고, 아래는 최근 “AI 표절/부정행위” 이슈를 다룬 기사들이라, 정책 설계 참고용으로 같이 남겨둘게요:

* [theguardian.com](https://www.theguardian.com/education/2025/jun/15/thousands-of-uk-university-students-caught-cheating-using-ai-artificial-intelligence-survey?utm_source=chatgpt.com)
* [theguardian.com](https://www.theguardian.com/technology/2025/jun/23/theres-no-simple-solution-to-universities-ai-worries?utm_source=chatgpt.com)

[1]: https://www.frontiersin.org/journals/computer-science/articles/10.3389/fcomp.2025.1504725/full?utm_source=chatgpt.com "Plagiarism types and detection methods: a systematic survey of ..."
[2]: https://hastewire.com/blog/how-ai-detectors-identify-gpt-text-key-methods-explained?utm_source=chatgpt.com "How AI Detectors Identify GPT Text: Key Methods Explained"
[3]: https://journals.plos.org/plosone/article?id=10.1371%2Fjournal.pone.0319551&utm_source=chatgpt.com "Comparative analysis of text-based plagiarism detection techniques ..."
[4]: https://dl.acm.org/doi/fullHtml/10.1145/3345317?utm_source=chatgpt.com "Academic Plagiarism Detection: A Systematic Literature Review"
[5]: https://files.eric.ed.gov/fulltext/EJ1340053.pdf?utm_source=chatgpt.com "Automatic Detection of Plagiarism in Writing - ed"
[6]: https://hogonext.com/how-to-detect-plagiarism-with-embeddings/?utm_source=chatgpt.com "How to Detect Plagiarism with Embeddings - HogoNext"
[7]: https://link.springer.com/article/10.1007/s00701-025-06622-4?utm_source=chatgpt.com "Can we trust academic AI detective? Accuracy and limitations of AI ..."
[8]: https://writemywayai.com/2025/07/how-gpt-detectors-work-and-why-theyre-not-enough-for-fair-student-assessment/?utm_source=chatgpt.com "How GPT Detectors Work and Why They’re Not Enough for Fair Student ..."
